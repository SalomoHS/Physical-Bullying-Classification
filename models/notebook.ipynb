{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model\n",
    "from Bullying10k.braincog.utils import *\n",
    "from Bullying10k.Bullying10k import get_bullying10k_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data_loader):\n",
    "    start_time = timeit.default_timer()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(data_loader['train']):\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        probs = nn.Softmax(dim=1)(outputs)\n",
    "        preds = torch.max(probs, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / trainval_sizes['train']\n",
    "    epoch_acc = running_corrects.double() / trainval_sizes['train']\n",
    "    wandb.log({\"accuracy\": epoch_acc, \"loss\": epoch_loss})\n",
    "    print(\"[{}] Epoch: {}/{} Loss: {} Acc: {}\".format('train', epoch+1, config.EPOCHS, epoch_loss, epoch_acc))\n",
    "    stop_time = timeit.default_timer()\n",
    "    print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, optimizer, data_loader):\n",
    "    start_time = timeit.default_timer()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in tqdm(data_loader['val']):\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        probs = nn.Softmax(dim=1)(outputs)\n",
    "        preds = torch.max(probs, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / trainval_sizes['val']\n",
    "    epoch_acc = running_corrects.double() / trainval_sizes['val']\n",
    "    wandb.sklearn.plot_confusion_matrix(all_labels, all_preds, [i for i in range(8)])\n",
    "    print(\"[{}] Epoch: {}/{} Loss: {} Acc: {}\".format('val', epoch+1, config.EPOCHS, epoch_loss, epoch_acc))\n",
    "    stop_time = timeit.default_timer()\n",
    "    print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"Bullying10K - C3D\",\n",
    "    name=\"Fine Tune\"\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "config.BATCH_SIZE = 4\n",
    "config.STEP = 30\n",
    "config.GAP = 4\n",
    "config.SIZE = 112\n",
    "config.NUM_CLASSES = 6\n",
    "config.LEARNING_RATE = 1e-5\n",
    "config.EPOCHS = 30\n",
    "config.SEED = 42\n",
    "config.WEIGHT_DECAY = 1e-4\n",
    "\n",
    "torch.manual_seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "train_dataloader,test_dataloader,_,_ = get_bullying10k_data(batch_size = config.BATCH_SIZE, step = config.STEP,\n",
    "                                                            gap = config.GAP, size = config.SIZE)\n",
    "val_dataloader = train_dataloader\n",
    "trainval_loaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "trainval_sizes = {x: len(trainval_loaders[x].dataset) for x in ['train', 'val']}\n",
    "test_size = len(test_dataloader.dataset)\n",
    "\n",
    "c3d = model.C3D.C3D(num_classes = config.NUM_CLASSES, pretrained = False, inchannel = 2)\n",
    "c3d.to(device)\n",
    "train_params = [{'params': model.C3D.get_1x_lr_params(c3d), 'lr': config.LEARNING_RATE},\n",
    "                {'params': model.C3D.get_10x_lr_params(c3d), 'lr': config.LEARNING_RATE * 10}]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(train_params, lr = config.LEARNING_RATE, \n",
    "                       weight_decay = config.WEIGHT_DECAY)\n",
    "\n",
    "wandb.watch(c3d, log=\"all\")\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train(c3d,criterion,optimizer,trainval_loaders)\n",
    "\n",
    "for epoch in range(1):\n",
    "    validate(c3d,criterion,optimizer,trainval_loaders)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"Bullying10K - I3D\",\n",
    "    name=\"Testing\"\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "config.BATCH_SIZE = 4\n",
    "config.STEP = 30\n",
    "config.GAP = 4\n",
    "config.SIZE = 112\n",
    "config.NUM_CLASSES = 6\n",
    "config.LEARNING_RATE = 1e-5\n",
    "config.EPOCHS = 30\n",
    "config.SEED = 42\n",
    "config.WEIGHT_DECAY = 1e-4\n",
    "\n",
    "torch.manual_seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "train_dataloader,test_dataloader,_,_ = get_bullying10k_data(batch_size = config.BATCH_SIZE,step = config.STEP,\n",
    "                                                            gap = config.GAP, size = config.SIZE)\n",
    "val_dataloader = train_dataloader\n",
    "trainval_loaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "trainval_sizes = {x: len(trainval_loaders[x].dataset) for x in ['train', 'val']}\n",
    "test_size = len(test_dataloader.dataset)\n",
    "\n",
    "i3d = model.I3D.Inception3D(num_classes = config.NUM_CLASSES)\n",
    "i3d.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(i3d.parameters(), lr = config.LEARNING_RATE, \n",
    "                       weight_decay = config.WEIGHT_DECAY)\n",
    "\n",
    "wandb.watch(i3d, log=\"all\")\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train(i3d,criterion,optimizer,trainval_loaders)\n",
    "\n",
    "for epoch in range(1):\n",
    "    validate(i3d,criterion,optimizer,trainval_loaders)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"Bullying10K - X3D\",\n",
    "    name=\"Testing\"\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "config.BATCH_SIZE = 4\n",
    "config.STEP = 30\n",
    "config.GAP = 4\n",
    "config.SIZE = 112\n",
    "config.NUM_CLASSES = 6\n",
    "config.LEARNING_RATE = 1e-5\n",
    "config.EPOCHS = 50\n",
    "config.SEED = 42\n",
    "config.WEIGHT_DECAY = 1e-4\n",
    "config.LAYERS = (4, 4, 4, 4)\n",
    "config.CHANNELS =(64, 256, 512,1024)\n",
    "config.EXPANSION = 4\n",
    "\n",
    "torch.manual_seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "train_dataloader,test_dataloader,_,_ = get_bullying10k_data(batch_size = config.BATCH_SIZE, step = config.STEP,\n",
    "                                                            gap = config.GAP, size = config.SIZE)\n",
    "val_dataloader = train_dataloader\n",
    "trainval_loaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "trainval_sizes = {x: len(trainval_loaders[x].dataset) for x in ['train', 'val']}\n",
    "test_size = len(test_dataloader.dataset)\n",
    "\n",
    "x3d = model.X3D.X3D(num_classes = config.NUM_CLASSES, layers = config.LAYERS, \n",
    "                    channels=config.CHANNELS, expansion = config.EXPANSION)\n",
    "x3d.to(device)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(x3d.parameters(), lr = config.LEARNING_RATE, \n",
    "                       weight_decay = config.WEIGHT_DECAY)\n",
    "\n",
    "wandb.watch(x3d, log=\"all\")\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train(x3d,criterion,optimizer,trainval_loaders)\n",
    "\n",
    "for epoch in range(1):\n",
    "    validate(x3d,criterion,optimizer,trainval_loaders)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
