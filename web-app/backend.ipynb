{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbGkmwKoXfN1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from fastapi import FastAPI\n",
        "from fastapi import File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "from io import BytesIO\n",
        "sys.path.append('/content/drive/MyDrive/Skripsi/Script/Bullying10K/')\n",
        "from readdata import *\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqYcuQ4YXyvP"
      },
      "outputs": [],
      "source": [
        "class C3D(nn.Module):\n",
        "    \"\"\"\n",
        "    The C3D network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True, inchannel=3,step=16):\n",
        "        super(C3D, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(inchannel, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
        "\n",
        "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
        "        if step==16:\n",
        "            self.fc6 = nn.Linear(8192, 4096)\n",
        "            self.fc7 = nn.Linear(4096, 4096)\n",
        "            self.fc8 = nn.Linear(4096, num_classes)\n",
        "        elif step==10:\n",
        "            self.fc6 = nn.Linear(8192, 4096)\n",
        "            self.fc7 = nn.Linear(4096, 4096)\n",
        "            self.fc8 = nn.Linear(4096, num_classes)\n",
        "        elif step==4:\n",
        "            self.fc6 = nn.Linear(8192, 4096)\n",
        "            self.fc7 = nn.Linear(4096, 4096)\n",
        "            self.fc8 = nn.Linear(4096, num_classes)\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.__init_weight()\n",
        "\n",
        "        if pretrained:\n",
        "            self.__load_pretrained_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.relu(self.conv3a(x))\n",
        "        x = self.relu(self.conv3b(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.relu(self.conv4a(x))\n",
        "        x = self.relu(self.conv4b(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.relu(self.conv5a(x))\n",
        "        x = self.relu(self.conv5b(x))\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        x = x.view(-1, 8192)\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc7(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc8(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def __load_pretrained_weights(self):\n",
        "        \"\"\"Initialiaze network.\"\"\"\n",
        "        corresp_name = {\n",
        "                        # Conv1\n",
        "                        \"features.0.weight\": \"conv1.weight\",\n",
        "                        \"features.0.bias\": \"conv1.bias\",\n",
        "                        # Conv2\n",
        "                        \"features.3.weight\": \"conv2.weight\",\n",
        "                        \"features.3.bias\": \"conv2.bias\",\n",
        "                        # Conv3a\n",
        "                        \"features.6.weight\": \"conv3a.weight\",\n",
        "                        \"features.6.bias\": \"conv3a.bias\",\n",
        "                        # Conv3b\n",
        "                        \"features.8.weight\": \"conv3b.weight\",\n",
        "                        \"features.8.bias\": \"conv3b.bias\",\n",
        "                        # Conv4a\n",
        "                        \"features.11.weight\": \"conv4a.weight\",\n",
        "                        \"features.11.bias\": \"conv4a.bias\",\n",
        "                        # Conv4b\n",
        "                        \"features.13.weight\": \"conv4b.weight\",\n",
        "                        \"features.13.bias\": \"conv4b.bias\",\n",
        "                        # Conv5a\n",
        "                        \"features.16.weight\": \"conv5a.weight\",\n",
        "                        \"features.16.bias\": \"conv5a.bias\",\n",
        "                         # Conv5b\n",
        "                        \"features.18.weight\": \"conv5b.weight\",\n",
        "                        \"features.18.bias\": \"conv5b.bias\",\n",
        "                        # fc6\n",
        "                        \"classifier.0.weight\": \"fc6.weight\",\n",
        "                        \"classifier.0.bias\": \"fc6.bias\",\n",
        "                        # fc7\n",
        "                        \"classifier.3.weight\": \"fc7.weight\",\n",
        "                        \"classifier.3.bias\": \"fc7.bias\",\n",
        "                        }\n",
        "\n",
        "        # p_dict = torch.load(\"C:\\\\Users\\\\isalo\\\\Documents\\\\Skripsi\\\\Program\\\\Backend\\\\c3d-pretrained.pth\")\n",
        "        s_dict = self.state_dict()\n",
        "        for name in p_dict:\n",
        "            if name not in corresp_name:\n",
        "                continue\n",
        "            s_dict[corresp_name[name]] = p_dict[name]\n",
        "        self.load_state_dict(s_dict)\n",
        "\n",
        "    def __init_weight(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                torch.nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "def get_1x_lr_params(model):\n",
        "    \"\"\"\n",
        "    This generator returns all the parameters for conv and two fc layers of the net.\n",
        "    \"\"\"\n",
        "    b = [model.conv1, model.conv2, model.conv3a, model.conv3b, model.conv4a, model.conv4b,\n",
        "         model.conv5a, model.conv5b, model.fc6, model.fc7]\n",
        "    for i in range(len(b)):\n",
        "        for k in b[i].parameters():\n",
        "            if k.requires_grad:\n",
        "                yield k\n",
        "\n",
        "def get_10x_lr_params(model):\n",
        "    \"\"\"\n",
        "    This generator returns all the parameters for the last fc layer of the net.\n",
        "    \"\"\"\n",
        "    b = [model.fc8]\n",
        "    for j in range(len(b)):\n",
        "        for k in b[j].parameters():\n",
        "            if k.requires_grad:\n",
        "                yield k\n",
        "\n",
        "\n",
        "def model_predict(file):\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    data = readnplong(file) # return npy array loileoks like pickle load\n",
        "\n",
        "    data=[i for i  in data]\n",
        "    loc=np.random.choice(len(data)-30*4+1)\n",
        "    data=data[loc:loc+30*4 :4]\n",
        "    frame=np.zeros((len(data),2,260,346),dtype=float)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        frame=event2frame(data[i],i,frame)\n",
        "\n",
        "    data=frame\n",
        "    data = data.reshape(2, 30, 260, 346)\n",
        "    frame=train_transform(data)\n",
        "\n",
        "    outputs = c3d(frame.unsqueeze(0))\n",
        "    probs = nn.Softmax(dim=1)(outputs)\n",
        "    # preds_tensor = torch.max(probs, 1)[1]\n",
        "    confidence, prediction_tensor = torch.max(probs, dim=1)\n",
        "    prediction = \"\"\n",
        "    if confidence.item() > 0.9:\n",
        "      if prediction_tensor.item() == 0:\n",
        "        prediction = \"slapping\"\n",
        "      elif prediction_tensor.item() == 1:\n",
        "        prediction = \"kicking\"\n",
        "      elif prediction_tensor.item() == 2:\n",
        "        prediction = \"punching\"\n",
        "      elif prediction_tensor.item() == 3:\n",
        "        prediction = \"pushing\"\n",
        "      elif prediction_tensor.item() == 4:\n",
        "        prediction = \"strangling\"\n",
        "      elif prediction_tensor.item() == 5:\n",
        "        prediction = \"hairgrabs\"\n",
        "\n",
        "      return prediction\n",
        "    else:\n",
        "      return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP29wZOTX7OK"
      },
      "outputs": [],
      "source": [
        "def resize_tensor(x, size):\n",
        "    return F.interpolate(x, size=[size, size], mode='bilinear', align_corners=True)\n",
        "\n",
        "def preprocess_input(x):\n",
        "    return torch.tensor(x, dtype=torch.float)\n",
        "\n",
        "def apply_resize(x, size):\n",
        "    return resize_tensor(x, size)\n",
        "\n",
        "def resize_and_preprocess(x, size):\n",
        "    x = preprocess_input(x)\n",
        "    x = apply_resize(x, size)\n",
        "    # print(x.shape)\n",
        "    return x\n",
        "\n",
        "def transform(x):\n",
        "    return resize_and_preprocess(x, 112)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transform,\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transform,\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTxLan09YijE"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "c3d = C3D(num_classes=6, pretrained=False,inchannel=2)\n",
        "train_params = [{'params': get_1x_lr_params(c3d), 'lr': 1e-5},\n",
        "                {'params': get_10x_lr_params(c3d), 'lr': 1e-5 * 10}]\n",
        "optimizer = optim.Adam(train_params,lr=1e-5, weight_decay=1e-4)\n",
        "c3d.to(device)\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Skripsi/c3d.pth', weights_only=True, map_location=torch.device('cpu'))\n",
        "c3d.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FWJMG17YSHG"
      },
      "outputs": [],
      "source": [
        "# %%writefile main.py\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n",
        "@app.post(\"/upload\")\n",
        "async def upload(file: UploadFile):\n",
        "    file_content = await file.read()\n",
        "    file_stream = BytesIO(file_content)\n",
        "    prediction = model_predict(file_stream)\n",
        "\n",
        "    return JSONResponse(content={\"filename\": file.filename, \"preds\":str(prediction)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA8qz1wkY66a",
        "outputId": "35bd7451-27f9-46c4-ecdc-54b2ac730144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [245]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://1830-34-19-14-171.ngrok-free.app\n",
            "INFO:     103.80.236.168:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     149.154.161.200:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"GET /upload HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.47.133.65:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "INFO:     103.80.236.168:0 - \"POST /upload HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "# Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "auth_token = \"2objlYMWyeFYSA1SAbZqcLtc890_3Ab5n3uUwH5oqAZKKb1V8\"\n",
        "\n",
        "# Set the authtoken\n",
        "ngrok.set_auth_token(auth_token)\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
